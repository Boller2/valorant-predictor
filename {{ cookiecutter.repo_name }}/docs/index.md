---
hide:
  - navigation
---
# {{ cookiecutter.project_name }}
---
Based on [DIGG förtroendemodell](https://www.digg.se/publicerat/publikationer/2020/testa-ny-teknik-for-automatisering-inom-offentlig-forvaltning)
## Summary

A layman's summary of this project.

| Type              | Process, Model or Algorithm |
| ----------------- | --------------------------- |
| In                |                             |
| Out               |                             |
| Included in       |                             |
| Architecture      |                             |
| Document Version  |                             |
| Algorithm Version |                             |

### Usage

Why was this developed? What was the purpose? What has been the goals? Areas of use?


### Performance

How well does it work? (describe in simple terms)


### Limitations 

When does it not work as well as intended (must include concrete examples, pictures if possible), either due to intentional delimitations or unintended side effects.

### Process overview

Applies only to description of the process.
A simple process sketch with input data, sub-processes/models/algorithms, and output data

## Model information

Person or organization that developed the process/model/algorithm. When the process/model/algorithm was developed and its version.


### Architecture

Only applies to models & algorithms.

Basics about the architecture of the model/algorithm. In the case of a well-known model/algorithm, it may be sufficient to indicate its name and configuration as well as a link to its article with more information, otherwise a short summary is also needed. This should give people with knowledge of AI an understanding of limitations and reports
built into the model architecture itself.

### Technical platform

Only applies to processes.

Describe in words or pictures the chosen technical platform, take into account and pay attention to any cloud solutions.

### Training

Which parameters were used during training, e.g. number of epochs, batch size, loss function, learning rate, etc.

### Limitations

More detailed information about limitations and delimitations.

### Implementation details

For example, use of frameworks, software, etc.

### Articles or other resources for more information

Links to external resources, e.g. articles where the process/model/algorithm is introduced, or others that had similar use or as by another
reason is relevant.

### License

How is the process/model/algorithm licensed? What is required to use it?

### Contact person

Who should you contact for more information?

### Intended use

Primary intended uses and users.

### Use cases outside the scope of application

Alternative conceivable or actual use cases, for example with specific reports or comments.

## Factors

### Relevant factors

The factors that can affect the process/model/algorithm. There are three main factors: Different groups of objects, e.g. age and sex in a model for face recognition, building purpose and building size in a model for finding buildings or different length of sentences in an NLP model.

The impact of various instruments, e.g. camera model and processing methods. The environment, e.g. lighting, location, etc.

### Evaluation factors

The factors (mentioned in 4.1.) that have been evaluated. Why have they been evaluated or not (e.g. because it was not available or considered to be
relevant)?

## Evaluation of the model

Brief (1-2 sentences) description of the measurements used.

### Result

The performance of the process/model/algorithm described with numbers and graphs for the whole.

### User results

Only applies to processes.

Results from real-world use. May be in a test period or in production (whichever is to be specified). Should give an indication of the process
performance, Example metrics: User rating, number of retests and percentage that changed the result, acceptance sampling.

### Unitary results

What is the performance of the model for the individual factors (e.g. different genders, building purposes or sentence lengths) described with numbers and graphs for
the whole?

### Thresholds and comparisons

Thresholds for when the process/model/algorithm (in our opinion) is applicable (eg a requirement for precision/recall from "higher instance"), comparisons with others
processes/models/algorithms and methods, etc.

### Evaluation method

How have the evaluation values (e.g. precision/recall) been calculated? Can refer to external information if unchanged standard methods are used and a custom description adds nothing.

## Data

### Evaluation data

Information om det data som använts för att genomföra utvärderingen (källa, utbredning, förbehandling, m.m.). uppmärksamma särskilt om det finns
personuppgifter eller skyddsvärd information i utvärderingsdata.

### Training data

Information about the data used to train the model (source, distribution, preprocessing, etc.). pay particular attention to whether there is personal data or
information worthy of protection in evaluation data.

## Monitoring, logging and profiling

Describe whether the system generates logs and any form of monitoring. Pay particular attention to human interaction with these logs or monitoring

## Ethical aspects

The European Commission's Ethical Guidelines for Trusted AI sets out three components of its framework for Trusted AI: Includes, but is not limited to
to: Legal AI, Ethical AI and Robust AI. Ethical AI in turn encompasses four principles:
- Respect for human autonomy
- Prevention of injury
- Justice
- Explainability
These principles are explained in detail in the guidelines. They can be useful as a guide for the report made under this heading.

## Legal aspects

Requirements placed on the process/model/algorithm based on current laws and regulations. May have partial overlap with ethical aspects, e.g. current
personal data. The division that applies is that the chapter Ethical positions should handle the ethical side ("should one") and Legal
aspects dealing with the legal side ("can one").

### Privacy legislation

Pay particular attention to the data that is used and then in relation to e.g. GDPR

### Privacy or other protection legislation

Consider what privacy information is relevant to pay attention to

### review and appeals

For processes only. Can the decision be reviewed (by a human administrator) or appealed? How?

### Supervision

Is there someone supervising? External or internal? Authority, company or other?

## Reports and recommendations

Are there any additional aspects to consider that have not been addressed in another heading? Indicates e.g. the results that more tests are needed? Is there
any factors/groups not covered by the data used? Are there any other reports or recommendations that a user or further developer of
model should consider?
