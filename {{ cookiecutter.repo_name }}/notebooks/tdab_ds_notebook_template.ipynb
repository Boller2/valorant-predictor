{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2ee9a116",
      "metadata": {
        "id": "2ee9a116"
      },
      "source": [
        "# T-DAB Data Science Notebook Template\n",
        "\n",
        "### Objectives\n",
        "1. Make it easy for you and your colleagues to reuse your code\n",
        "2. Make your code look really polished and professional\n",
        "3. Save time!\n",
        "\n",
        "### Principles\n",
        "- üì¶ Modular: Code is broken into small, independent parts (like functions) that each do one thing. Code you‚Äôre reusing lives in a single central place.\n",
        "- ‚úîÔ∏è Correct: Your code does what you say/think it does.\n",
        "- üìñ Readable: It‚Äôs easy to read the code and understand what it does. Variable names are informative and code has up-to-date comments and docstrings.\n",
        "- üíÖ Stylish: Code follows a single, consistent style (e.g. the Tidyverse style guide for R, PEP 8 for Python code)\n",
        "- üõ†Ô∏è Versatile: Solves a problem that will happen more than once and anticipates variation in the data.\n",
        "- üí° Creative: Solves a problem that hasn‚Äôt already been solved or is a clear improvement over an existing solution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "639c2bc2",
      "metadata": {
        "id": "639c2bc2"
      },
      "source": [
        "### General Guidelines\n",
        "\n",
        "- Structure your Notebook: give your notebook a title (H1 header) and a meaningful preamble to describe its purpose and contents.\n",
        "- Use headings (H2, H3...) and documentation in Markdown cells to structure your notebook and explain your workflow steps.\n",
        "- Not all sections described here will be required. I.e.: an EDA notebook may only include Importing Data, Pre-processing and Data Analysis.\n",
        "\n",
        "#### To further discuss\n",
        "- Use of **notebook template** with general section guidelines (somewhat flexible) and common imports.\n",
        "- Define **naming convention** for all T-DAB notebooks:\n",
        "\n",
        "  - Current Jupyter Notebooks naming convention is a number (for ordering), the creator's initials, and a short `-` delimited description. For example: `1.0-jqp-initial-data-exploration`\n",
        "  - Discuss ordering: **should this be independent to each author to indicate reading order?** \n",
        "  - Suggestion: **if ordering is per author, we might prefer to start convention with initials and then include sorting numbers**\n",
        "\n",
        "\n",
        "\n",
        "#### Potential future additions\n",
        "\n",
        "- The **toc2** extension can automatically create heading numbers and a Table of Contents, both in a sidebar (optionally a floating window) and in a markdown cell. The highlighting indicates your current position in the document ‚Äî this will help you keep oriented in long notebooks.\n",
        "- The **Collapsible Headings** extension allows you to hide entire sections of code, thereby letting you focus on your current workflow stage.\n",
        "- The **Jupyter Snippets** extension allows you to conveniently insert often needed code blocks, e.g. your typical import statements. Or, as an even simpler approach, we could just provide a generic import cell as in the template below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "frSuUot8alNO",
      "metadata": {
        "id": "frSuUot8alNO"
      },
      "source": [
        "# Beginning of Notebook Template..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cbe56b6",
      "metadata": {
        "id": "2cbe56b6"
      },
      "source": [
        "# Notebook Title\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Short description of the contents of the following notebook, should match the one included in repository's `README.md` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa0621a",
      "metadata": {
        "id": "cfa0621a"
      },
      "outputs": [],
      "source": [
        "# Load the \"autoreload\" extension so that code can change\n",
        "%load_ext autoreload\n",
        "# Always reload modules so that as you change code in src, it gets loaded\n",
        "%autoreload 2\n",
        "\n",
        "# Import all relevant libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1264833",
      "metadata": {
        "id": "c1264833"
      },
      "source": [
        "## Import data\n",
        "\n",
        "- Import all relevant files into DataFrames\n",
        "- Raw files should be stored in repository `data` folder unless size is an impediment (order of few MBs)\n",
        "- Use descriptive yet concise names to define DataFrame objects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de22b21d",
      "metadata": {
        "id": "de22b21d"
      },
      "outputs": [],
      "source": [
        "# Read data\n",
        "# df_raw_1 = pd.read_csv('./data/sample_data.csv')\n",
        "# df_raw_2 = pd.read_csv('./data/sample_data.csv')\n",
        "\n",
        "# Preview data\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9f2ca19",
      "metadata": {
        "id": "c9f2ca19"
      },
      "source": [
        "## Data cleaning & pre-processing\n",
        "\n",
        "- Include all cleaning and pre-processing steps required before modeling\n",
        "- If preprocessing is to be performed on several datasets try to wrap reusable code into a function\n",
        "- Include **docstrings** describing every function purpose as well as its `input` and `output` parameters\n",
        "- If possible merge all raw files into a single clean DataFrame at the end of the cleaning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addeacc9",
      "metadata": {
        "id": "addeacc9"
      },
      "outputs": [],
      "source": [
        "# Data cleaning and pre-processing\n",
        "def clean_data(df, param1, param2, *args, **kwargs):\n",
        "    \n",
        "    \"\"\"\n",
        "    This function wraps all the required cleaning and pre-processing steps\n",
        "    \n",
        "    Args:\n",
        "        df: pandas DataFrame containing raw data\n",
        "        param1: The first parameter.\n",
        "        param2: The second parameter.\n",
        "\n",
        "    Returns:\n",
        "        clean_df: a DataFrame containing cleaned data\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Include all relevant data wrangling functions/ste[s]\n",
        "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
        "    df = df.drop_duplicates()\n",
        "    ...\n",
        "    df['col_1'].fillna(method = 'ffill', inplace=True)\n",
        "    df['col_2'].interpolate(method='linear', axis=0, limit=None, inplace = True)\n",
        "    df.dropna(axis=0, thresh=len(df.columns)/2, inplace=True)\n",
        "    \n",
        "    return clean_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de5cf42",
      "metadata": {
        "id": "2de5cf42"
      },
      "outputs": [],
      "source": [
        "# If more than one DataFrame is provided we can try merging them after cleaning\n",
        "# df = pd.merge(df_1, df_2, how=\"left\", on='index', sort=True).set_index('index')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48730edf",
      "metadata": {
        "id": "48730edf"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "- In this sub-section we obtain all required summary statistics and visualizations \n",
        "- Ideally, we should build reusable functions both for plotting and obtaining summary statistics\n",
        "- Once functions have been defined the cells calling the required code should follow below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdc110ba",
      "metadata": {
        "id": "bdc110ba"
      },
      "outputs": [],
      "source": [
        "# Example function to obtain summary statistics\n",
        "def get_summary(df):\n",
        "    \n",
        "    \"\"\"\n",
        "    This function takes a DataFrame with data and returns summary statistics on the columns it contains\n",
        "    \n",
        "    Args:\n",
        "        df: pandas DataFrame containing data to analyze\n",
        "\n",
        "    Returns:\n",
        "        summary_df: a DataFrame containing summary statistics on df columns\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # Get a whole bunch of stats\n",
        "    summary_df = df.describe().transpose()\n",
        "    \n",
        "    # Count NANs\n",
        "    summary_df['number_nan'] = df.shape[0] - summary_df['count']\n",
        "    \n",
        "    # Count unique values\n",
        "    summary_df['number_distinct'] = df.apply(lambda x: len(pd.unique(x)), axis=0) \n",
        "    \n",
        "    # Count unique values\n",
        "    summary_df['median'] = df.median()\n",
        "    \n",
        "    # Print DateTime information\n",
        "    try:\n",
        "        print(df['DateTime'].describe(datetime_is_numeric=True))\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return summary_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e1e95b",
      "metadata": {
        "id": "c1e1e95b"
      },
      "outputs": [],
      "source": [
        "# Example function to plot a Histogram + Boxplot \n",
        "def plot_metrics(df, metric = 'metric_name', bins = 30, title = 'Distribution', xlabel = 'x', ylabel= 'y'):\n",
        "\n",
        "    \"\"\"\n",
        "    This function takes a clean DataFrame and outputs a Histogram and a Boxplot of a selected metric\n",
        "    \n",
        "        Args:\n",
        "        df (DataFrame): pandas DataFrame containing clean data\n",
        "        metric (str): string specifying which metric to plot\n",
        "        bins (int): number specifying number of bins\n",
        "        title (str): plot title\n",
        "        xlabel (str): label for x axis\n",
        "        ylabel (str): label for y axis\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # Extract raw ads\n",
        "    metrics = df[metric]\n",
        "\n",
        "    # Create a figure for 2 subplots\n",
        "    fig, ax = plt.subplots(2,1,figsize = (12,12))\n",
        "    # Plot histogram\n",
        "    ax[0].hist(metrics, bins = bins)\n",
        "    ax[0].axvline(metrics.mean(), color = 'magenta', linestyle = 'dashed', linewidth = 2)\n",
        "    ax[0].axvline(metrics.median(), color = 'cyan', linestyle = 'dashed', linewidth = 2)\n",
        "    ax[0].set_xlabel(metric, fontsize = 16)\n",
        "    ax[0].set_ylabel('counts', fontsize = 16)\n",
        "    # Plot boxplot\n",
        "    ax[1].boxplot(metrics, vert = False)\n",
        "    ax[1].set_xlabel(xlabel, fontsize = 16)\n",
        "    ax[1].set_ylabel(ylabel, fontsize = 16)\n",
        "\n",
        "    # Add title\n",
        "    fig.suptitle(title)\n",
        "\n",
        "    # Show figure\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c7497e",
      "metadata": {
        "id": "d9c7497e"
      },
      "source": [
        "## Modeling\n",
        "- This section will contain all the models we would like to train using our pre-processed data\n",
        "- If several models are produced, we should include a subsection per model identified by a markdown (H3) sub-header\n",
        "- Typical subsections that we want to include here:\n",
        "    - Import all ML/model relevant modules\n",
        "    - Perform Feature Engineering and Feature Selection\n",
        "    - Proper Train, Validation & (if required) Test split \n",
        "    - All `seed` parameters to allow experiment reproducibility should be set here as well\n",
        "- As usual, code should be modularized into functions when possible\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "242794ec",
      "metadata": {
        "id": "242794ec"
      },
      "source": [
        "## Evaluation\n",
        "- This section will contain all the code required to evaluate our models \n",
        "- Results could be presented in the form of plots and/or figures \n",
        "- Ideally, one should provide functions that take all parameters required by the model to allow comparison between different model configurations while minimizing the amount of code\n",
        "- All plotting, evaluation and auxiliary functions should be included at the top of the section. Evaluation cells should follow and included as little code as possible\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23152ae0",
      "metadata": {
        "id": "23152ae0"
      },
      "source": [
        "## References for best Software Engineering Practices for Jupyter Notebooks\n",
        "\n",
        "1. [Manage your Data Science project structure in early stage](https://towardsdatascience.com/manage-your-data-science-project-structure-in-early-stage-95f91d4d0600)\n",
        "2. [Six steps to more professional data science code ](https://www.kaggle.com/rtatman/six-steps-to-more-professional-data-science-code)\n",
        "3. [Jupyter Notebook Best Practices](https://towardsdatascience.com/jupyter-notebook-best-practices-f430a6ba8c69)\n",
        "4. [Example Google Style Python Docstring](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f529389b",
      "metadata": {
        "id": "f529389b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tdab_ds_notebook_template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
